{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.multioutput import MultiOutputRegressor\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T09:42:34.334337Z","iopub.execute_input":"2025-12-18T09:42:34.335316Z","iopub.status.idle":"2025-12-18T09:42:34.375198Z","shell.execute_reply.started":"2025-12-18T09:42:34.335277Z","shell.execute_reply":"2025-12-18T09:42:34.374260Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# =========================\n# 2. LOAD DATA (3 LINKS)\n# =========================\ntrain_df = pd.read_csv(\"/kaggle/input/your-dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/your-dataset/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/your-dataset/sample_submission.csv\")\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape :\", test_df.shape)\nprint(\"Sample submission shape:\", sample_submission.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 3. TARGET & FEATURES\n# =========================\n# Multi-output regression targets\nTARGET_COLS = sample_submission.columns[1:].tolist()\n\nX = train_df.drop(columns=TARGET_COLS)\ny = train_df[TARGET_COLS]\n\nX_test_final = test_df.copy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 4. TRAINâ€“VALID SPLIT\n# =========================\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=42\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 5. DATA PRE-PROCESSING\n# =========================\ncat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\nnum_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", Pipeline([\n            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n        ]), cat_cols),\n\n        (\"num\", Pipeline([\n            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n            (\"scaler\", StandardScaler())\n        ]), num_cols),\n    ]\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 6. MODEL SELECTION\n# =========================\nmodels = {\n    \"LinearRegression\": MultiOutputRegressor(\n        LinearRegression()\n    ),\n\n    \"RandomForest\": MultiOutputRegressor(\n        RandomForestRegressor(\n            n_estimators=300,\n            random_state=42,\n            n_jobs=-1\n        )\n    ),\n\n    \"XGBoost\": MultiOutputRegressor(\n        XGBRegressor(\n            n_estimators=300,\n            learning_rate=0.05,\n            max_depth=6,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            n_jobs=-1\n        )\n    ),\n\n    \"LightGBM\": MultiOutputRegressor(\n        LGBMRegressor(\n            n_estimators=300,\n            learning_rate=0.05,\n            n_jobs=-1\n        )\n    ),\n\n    \"CatBoost\": MultiOutputRegressor(\n        CatBoostRegressor(\n            iterations=300,\n            learning_rate=0.05,\n            depth=6,\n            verbose=0\n        )\n    )\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 7. TRAIN, EVALUATE & BENCHMARK\n# =========================\nresults = []\nbest_model = None\nbest_rmse = np.inf\n\nfor name, model in models.items():\n    print(f\"\\nTraining {name} ...\")\n\n    pipe = Pipeline([\n        (\"pre\", preprocess),\n        (\"model\", model)\n    ])\n\n    pipe.fit(X_train, y_train)\n\n    preds = pipe.predict(X_valid)\n\n    rmse = np.sqrt(mean_squared_error(y_valid, preds))\n    r2 = r2_score(y_valid, preds, multioutput=\"uniform_average\")\n\n    results.append({\n        \"Model\": name,\n        \"RMSE\": rmse,\n        \"R2\": r2\n    })\n\n    print(\"RMSE:\", rmse)\n    print(\"R2  :\", r2)\n\n    if rmse < best_rmse:\n        best_rmse = rmse\n        best_model = pipe\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 8. BENCHMARK TABLE\n# =========================\nbenchmark_df = pd.DataFrame(results).sort_values(\"RMSE\")\n\nprint(\"\\nMODEL BENCHMARK COMPARISON\")\nprint(benchmark_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 9. FINAL PREDICTION\n# =========================\nfinal_preds = best_model.predict(X_test_final)\n\nsubmission = pd.DataFrame(\n    final_preds,\n    columns=TARGET_COLS\n)\n\nsubmission.insert(\n    0,\n    sample_submission.columns[0],\n    test_df[sample_submission.columns[0]]\n    if sample_submission.columns[0] in test_df.columns\n    else np.arange(len(test_df))\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 10. SAVE SUBMISSION\n# =========================\nsubmission.to_csv(\"submission_final.csv\", index=False)\nprint(\"\\nsubmission_final.csv saved!\")\nprint(submission.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}